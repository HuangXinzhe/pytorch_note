{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型微调-torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 模型微调的流程\n",
    "- 在大规模数据上训练预训练模型（源模型）\n",
    "- 创建一个新的神经网络，该网络包含源模型的所有层，但最后一层除外\n",
    "- 为新模型定义一个新的输出层，并将其初始化为随机权重\n",
    "- 在小规模数据集上训练新模型，只更新新层的权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 使用已有模型结构\n",
    "- 传递pretrained参数\n",
    "    - 通过True或者False来决定是否使用预训练好的权重，在默认状态下pretrained = False，意味着我们不使用预训练得到的权重，当pretrained = True，意味着我们将使用在一些数据集上预训练得到的权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "resnet18 = models.resnet18()\n",
    "# resnet18 = models.resnet18(pretrained=False)  等价于与上面的表达式\n",
    "alexnet = models.alexnet()\n",
    "vgg16 = models.vgg16()\n",
    "squeezenet = models.squeezenet1_0()\n",
    "densenet = models.densenet161()\n",
    "inception = models.inception_v3()\n",
    "googlenet = models.googlenet()\n",
    "shufflenet = models.shufflenet_v2_x1_0()\n",
    "mobilenet_v2 = models.mobilenet_v2()\n",
    "mobilenet_v3_large = models.mobilenet_v3_large()\n",
    "mobilenet_v3_small = models.mobilenet_v3_small()\n",
    "resnext50_32x4d = models.resnext50_32x4d()\n",
    "wide_resnet50_2 = models.wide_resnet50_2()\n",
    "mnasnet = models.mnasnet1_0()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意事项：\n",
    "\n",
    "- 通常PyTorch模型的扩展为.pt或.pth，程序运行时会首先检查默认路径中是否有已经下载的模型权重，一旦权重被下载，下次加载就不需要下载了。\n",
    "\n",
    "- 一般情况下预训练模型的下载会比较慢，我们可以直接通过迅雷或者其他方式去 这里 查看自己的模型里面model_urls，然后手动下载，预训练模型的权重在Linux和Mac的默认下载路径是用户根目录下的.cache文件夹。在Windows下就是C:\\Users\\<username>\\.cache\\torch\\hub\\checkpoint。我们可以通过使用 torch.utils.model_zoo.load_url()设置权重的下载地址。\n",
    "\n",
    "- 如果觉得麻烦，还可以将自己的权重下载下来放到同文件夹下，然后再将参数加载网络。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.model = models.resnet50(pretrained=False)\n",
    "self.model.load_state_dict(torch.load('./model/resnet50-19c8e357.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 如果中途强行停止下载的话，一定要去对应路径下将权重文件删除干净，要不然可能会报错。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 训练特定层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "# 冻结参数的梯度\n",
    "feature_extract = True\n",
    "model = models.resnet18(pretrained=True)\n",
    "set_parameter_requires_grad(model, feature_extract)\n",
    "# 修改模型\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features=num_ftrs, out_features=4, bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之后在训练过程中，model仍会进行梯度回传，但是参数更新则只会发生在fc层。通过设定参数的requires_grad属性，我们完成了指定训练模型的特定层的目标，这对实现模型微调非常重要。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
