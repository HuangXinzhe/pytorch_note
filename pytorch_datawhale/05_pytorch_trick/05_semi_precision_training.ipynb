{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 半精度训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU的性能主要分为两部分：算力和显存\n",
    "- 算力：显卡计算的速度\n",
    "- 显存：同时放入多少数据用于计算\n",
    "\n",
    "PyTorch默认的浮点数存储方式用的是torch.float32，小数点后位数更多固然能保证数据的精确性，但绝大多数场景其实并不需要这么精确，只保留一半的信息也不会影响结果，也就是使用torch.float16格式。由于数位减了一半，因此被称为“半精度”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 半精度训练的设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast\n",
    "\n",
    "# 模型设置\n",
    "@autocast()   \n",
    "def forward(self, x):\n",
    "    ...\n",
    "    return x\n",
    "\n",
    "# 训练过程\n",
    "for x in train_loader:\n",
    "\tx = x.cuda()\n",
    "\twith autocast():\n",
    "            output = model(x)\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 注意：\n",
    "半精度训练主要适用于数据本身的size比较大（比如说3D图像、视频等）。当数据本身的size并不大时（比如手写数字MNIST数据集的图片尺寸只有28*28），使用半精度训练则可能不会带来显著的提升"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
