{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hook\n",
    "使用 Hook 函数提取网络中的特征图进行可视化  \n",
    "\n",
    "Hook 函数是在不改变主体的情况下，实现额外功能。由于 PyTorch 是基于动态图实现的，因此在一次迭代运算结束后，一些中间变量如非叶子节点的梯度和特征图，会被释放掉。在这种情况下想要提取和记录这些中间变量，就需要使用 Hook 函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.Tensor.register_hook(hook)\n",
    "- 功能：注册一个反向传播 hook 函数，仅输入一个参数，为张量的梯度。\n",
    "hook函数：\n",
    "- hook(grad)\n",
    "    - 参数：\n",
    "        - grad：张量的梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor([1.], requires_grad=True)\n",
    "x = torch.tensor([2.], requires_grad=True)\n",
    "a = torch.add(w, x)\n",
    "b = torch.add(w, 1)\n",
    "y = torch.mul(a, b)\n",
    "\n",
    "# 保存梯度的 list\n",
    "a_grad = list()\n",
    "\n",
    "# 定义 hook 函数，把梯度添加到 list 中\n",
    "def grad_hook(grad):\n",
    "    a_grad.append(grad)\n",
    "\n",
    "# 一个张量注册 hook 函数\n",
    "handle = a.register_hook(grad_hook)\n",
    "\n",
    "y.backward()\n",
    "\n",
    "# 查看梯度\n",
    "print(\"gradient:\", w.grad, x.grad, a.grad, b.grad, y.grad)\n",
    "# 查看在 hook 函数里 list 记录的梯度\n",
    "print(\"a_grad[0]: \", a_grad[0])\n",
    "handle.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
