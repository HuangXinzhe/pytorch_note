{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch 中的模型保存与加载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型保存\n",
    "torch.save(obj, f, pickle_module, pickle_protocol=2, _use_new_zipfile_serialization=False)\n",
    "- 主要参数：\n",
    "    - obj：保存的对象，可以是模型。也可以是 dict。因为一般在保存模型时，不仅要保存模型，还需要保存优化器、此时对应的 epoch 等参数。这时就可以用 dict 包装起来。\n",
    "    - f：输出路径\n",
    "1. 方法一：\n",
    "- 保存整个 Module\n",
    "    - 这种方法比较耗时，保存的文件大\n",
    "    - torch.save(net, path)\n",
    "2. 方法二：\n",
    "- 只保存模型的参数\n",
    "    - 推荐这种方法，运行比较快，保存的文件比较小\n",
    "    - state_sict = net.state_dict()  \n",
    "      torch.save(state_sict, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from common_tools import set_seed\n",
    "\n",
    "\n",
    "class LeNet2(nn.Module):\n",
    "    def __init__(self, classes):\n",
    "        super(LeNet2, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16*5*5, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(84, classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def initialize(self):\n",
    "        for p in self.parameters():\n",
    "            p.data.fill_(2020)\n",
    "\n",
    "\n",
    "net = LeNet2(classes=2019)\n",
    "\n",
    "# \"训练\"\n",
    "print(\"训练前: \", net.features[0].weight[0, ...])\n",
    "net.initialize()\n",
    "print(\"训练后: \", net.features[0].weight[0, ...])\n",
    "\n",
    "path_model = \"./model.pkl\"\n",
    "path_state_dict = \"./model_state_dict.pkl\"\n",
    "\n",
    "# 保存整个模型\n",
    "torch.save(net, path_model)\n",
    "\n",
    "# 保存模型参数\n",
    "net_state_dict = net.state_dict()\n",
    "torch.save(net_state_dict, path_state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行完之后，文件夹中生成了```model.pkl``和model_state_dict.pkl，分别保存了整个网络和网络的参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型加载\n",
    "- torch.load\n",
    "    - torch.load(f, map_location=None, pickle_module, **pickle_load_args)\n",
    "    - 主要参数：\n",
    "        - f：文件路径\n",
    "        - map_location：指定存在 CPU 或者 GPU。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 方法一：\n",
    "- 加载整个 Module\n",
    "    - 如果保存的时候，保存的是整个模型，那么加载时就加载整个模型。这种方法不需要事先创建一个模型对象，也不用知道模型的结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = \"./model.pkl\"  \n",
    "net_load = torch.load(path_model)  \n",
    "print(net_load)\n",
    "\n",
    "\"\"\"\n",
    "LeNet2(\n",
    "  (features): Sequential(\n",
    "    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
    "    (1): ReLU()\n",
    "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
    "    (4): ReLU()\n",
    "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "  )\n",
    "  (classifier): Sequential(\n",
    "    (0): Linear(in_features=400, out_features=120, bias=True)\n",
    "    (1): ReLU()\n",
    "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
    "    (3): ReLU()\n",
    "    (4): Linear(in_features=84, out_features=2019, bias=True)\n",
    "  )\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 方法二：\n",
    "- 只加载模型的参数\n",
    "    - 如果保存的时候，保存的是模型的参数，那么加载时就参数。这种方法需要事先创建一个模型对象，再使用模型的load_state_dict()方法把参数加载到模型中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_state_dict = \"./model_state_dict.pkl\"\n",
    "state_dict_load = torch.load(path_state_dict)\n",
    "net_new = LeNet2(classes=2019)\n",
    "\n",
    "print(\"加载前: \", net_new.features[0].weight[0, ...])\n",
    "net_new.load_state_dict(state_dict_load)\n",
    "print(\"加载后: \", net_new.features[0].weight[0, ...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型的断点续训练\n",
    "在训练过程中，可能由于某种意外原因如断点等导致训练终止，这时需要重新开始训练。断点续练是在训练过程中每隔一定次数的 epoch 就保存模型的参数和优化器的参数，这样如果意外终止训练了，下次就可以重新加载最新的模型参数和优化器的参数，在这个基础上继续训练。\n",
    "下面的代码中，每隔 5 个 epoch 就保存一次，保存的是一个 dict，包括模型参数、优化器的参数、epoch。然后在 epoch 大于 5 时，就break模拟训练意外终止"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (epoch+1) % checkpoint_interval == 0:\n",
    "\n",
    "    checkpoint = {\"model_state_dict\": net.state_dict(),\n",
    "                  \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                  \"epoch\": epoch}\n",
    "    path_checkpoint = \"./checkpoint_{}_epoch.pkl\".format(epoch)\n",
    "    torch.save(checkpoint, path_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 epoch 大于 5 时，就break模拟训练意外终止"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if epoch > 5:\n",
    "    print(\"训练意外中断...\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "断点续训练的恢复"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_checkpoint = \"./checkpoint_4_epoch.pkl\"\n",
    "checkpoint = torch.load(path_checkpoint)\n",
    "\n",
    "net.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "start_epoch = checkpoint['epoch']\n",
    "\n",
    "scheduler.last_epoch = start_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "需要注意的是，还要设置scheduler.last_epoch参数为保存的 epoch。模型训练的起始 epoch 也要修改为保存的 epoch。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
